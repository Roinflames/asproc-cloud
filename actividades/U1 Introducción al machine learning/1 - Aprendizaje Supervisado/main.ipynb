{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae18ed7d",
   "metadata": {},
   "source": [
    "# Aprendizaje Supervisado - Ejemplo Titanic\n",
    "\n",
    "Este notebook realiza los siguientes pasos:\n",
    "1. Carga los datos de entrenamiento y prueba del Titanic.\n",
    "2. Preprocesa los datos para convertirlos a un formato numérico y manejar valores faltantes.\n",
    "3. Divide los datos de entrenamiento para poder evaluar el modelo.\n",
    "4. Entrena un modelo de clasificación (Random Forest).\n",
    "5. Evalúa el rendimiento del modelo usando la métrica de precisión (accuracy).\n",
    "6. Genera un archivo de predicciones para la competencia de Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "338438bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.7.2-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\rodrigo\\appdata\\roaming\\python\\python312\\site-packages (2.3.2)\n",
      "Requirement already satisfied: numpy>=1.22.0 in c:\\users\\rodrigo\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (1.26.4)\n",
      "Collecting scipy>=1.8.0 (from scikit-learn)\n",
      "  Using cached scipy-1.16.2-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Using cached joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\rodrigo\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\rodrigo\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\rodrigo\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\rodrigo\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Using cached scikit_learn-1.7.2-cp312-cp312-win_amd64.whl (8.7 MB)\n",
      "Using cached joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "Using cached scipy-1.16.2-cp312-cp312-win_amd64.whl (38.6 MB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.5.2 scikit-learn-1.7.2 scipy-1.16.2 threadpoolctl-3.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ab3955e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 0. Importar librerías necesarias ---\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61013635",
   "metadata": {},
   "source": [
    "## 1. Definición de rutas y variables\n",
    "\n",
    "Definimos las rutas de los archivos y las columnas que usaremos en el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b329b0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si ejecutas en Google Colab o Jupyter, adapta las rutas a tu entorno\n",
    "TRAIN_FILE_PATH = \"titanic/train.csv\"\n",
    "TEST_FILE_PATH = \"titanic/test.csv\"\n",
    "SUBMISSION_FILE_PATH = \"submission.csv\"\n",
    "\n",
    "FEATURES = ['Pclass', 'Sex', 'Age']\n",
    "TARGET = 'Survived'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223bb115",
   "metadata": {},
   "source": [
    "## 2. Cargar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca3efe42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando datos...\n",
      "Datos cargados exitosamente.\n",
      "Datos de entrenamiento: (891, 12)\n",
      "Datos de prueba: (418, 11)\n"
     ]
    }
   ],
   "source": [
    "print(\"Cargando datos...\")\n",
    "\n",
    "try:\n",
    "    train_df = pd.read_csv(TRAIN_FILE_PATH)\n",
    "    test_df = pd.read_csv(TEST_FILE_PATH)\n",
    "    print(\"Datos cargados exitosamente.\")\n",
    "    print(f\"Datos de entrenamiento: {train_df.shape}\")\n",
    "    print(f\"Datos de prueba: {test_df.shape}\")\n",
    "except FileNotFoundError as e:\n",
    "    print(\"Error: No se encontró el archivo.\")\n",
    "    print(f\"Ruta esperada: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6035e7c",
   "metadata": {},
   "source": [
    "## 3. Preprocesamiento de datos\n",
    "- Convertimos la columna `Sex` a numérico.\n",
    "- Rellenamos valores faltantes de `Age` con la **mediana** del conjunto de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adcab340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mediana de edad usada: 28.00\n"
     ]
    }
   ],
   "source": [
    "# Copias de seguridad para evitar modificaciones no deseadas\n",
    "train_processed = train_df.copy()\n",
    "test_processed = test_df.copy()\n",
    "\n",
    "# Mapear sexos a números\n",
    "sex_mapping = {'male': 0, 'female': 1}\n",
    "train_processed['Sex'] = train_processed['Sex'].map(sex_mapping)\n",
    "test_processed['Sex'] = test_processed['Sex'].map(sex_mapping)\n",
    "\n",
    "# Rellenar NaN en Age con la mediana del train\n",
    "median_age = train_processed['Age'].median()\n",
    "print(f\"Mediana de edad usada: {median_age:.2f}\")\n",
    "\n",
    "train_processed['Age'] = train_processed['Age'].fillna(median_age)\n",
    "test_processed['Age'] = test_processed['Age'].fillna(median_age)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb719c66",
   "metadata": {},
   "source": [
    "## 4. Entrenamiento y evaluación del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e3391d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos de entrenamiento: 712, Validación: 179\n",
      "Precisión en validación: 79.33%\n"
     ]
    }
   ],
   "source": [
    "# Dividir datos en train y validación\n",
    "X = train_processed[FEATURES]\n",
    "y = train_processed[TARGET]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Datos de entrenamiento: {len(X_train)}, Validación: {len(X_val)}\")\n",
    "\n",
    "# Entrenar modelo\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluación\n",
    "preds = clf.predict(X_val)\n",
    "accuracy = accuracy_score(y_val, preds)\n",
    "\n",
    "print(f\"Precisión en validación: {accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11690f2",
   "metadata": {},
   "source": [
    "## 5. Generar archivo de submission para Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7424f678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo guardado en submission.csv\n"
     ]
    }
   ],
   "source": [
    "# Predicciones en test\n",
    "X_test = test_processed[FEATURES]\n",
    "test_predictions = clf.predict(X_test)\n",
    "\n",
    "# Crear archivo de salida\n",
    "output = pd.DataFrame({\n",
    "    'PassengerId': test_processed.PassengerId,\n",
    "    'Survived': test_predictions\n",
    "})\n",
    "\n",
    "output.to_csv(SUBMISSION_FILE_PATH, index=False)\n",
    "print(f\"Archivo guardado en {SUBMISSION_FILE_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6435159",
   "metadata": {},
   "source": [
    "## ✅ Conclusión\n",
    "Hemos construido un pipeline básico de **Aprendizaje Supervisado** con Random Forest\n",
    "para el dataset del Titanic.  \n",
    "Este notebook es fácilmente ampliable:\n",
    "- Se pueden agregar más variables (Fare, SibSp, Embarked, etc.)\n",
    "- Se pueden probar distintos algoritmos de ML.\n",
    "- Se pueden ajustar hiperparámetros con GridSearchCV."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
