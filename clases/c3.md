[Presentación](https://gamma.app/docs/Almacenamiento-Bases-de-Datos-en-la-Nube-y-Procesamiento-Distribu-8z6ovw4gmvoqmv4?mode=doc)

# 📚 Clase 3 – Almacenamiento, Bases de Datos en la Nube y Procesamiento Distribuido
## 🎯 Objetivos de Aprendizaje
- Comprender los tipos de almacenamiento y bases de datos en la nube, incluyendo sus casos de uso.
- Explorar herramientas de ETL/ELT y la arquitectura de un Data Lake.
- Introducir conceptos de procesamiento paralelo y distribuido aplicados al Machine Learning.
- Practicar con Apache Spark y alternativas distribuidas en Python.
## ⏰ Agenda sugerida (4 horas)
### Bloque 1 (1h) – Almacenamiento y Bases de Datos en la Nube
Tipos de almacenamiento
- Object Storage (ejemplo: OCI Object Storage, AWS S3).
- Block Storage (volúmenes para VMs).
- File Storage (NFS gestionado en la nube).

👉 Demo práctica: crear un bucket en OCI Object Storage, subir un dataset CSV y mostrar cómo consultarlo desde una VM.

Bases de datos en la nube
- Relacionales: RDS, Azure SQL Database, Cloud SQL, Autonomous DB (OCI).
- NoSQL: DynamoDB, CosmosDB, Firestore.

Casos de uso: transaccional vs. alta escalabilidad.

👉 Demo práctica: consultar datos desde Autonomous DB usando la consola web.
### Bloque 2 (1h) – ETL/ELT y Data Lakes
Ingesta y transformación de datos en la nube (ETL/ELT)

- Herramientas: AWS Glue, Azure Data Factory, GCP Dataproc, OCI Data Integration.

Ejemplo: mover datos de Object Storage → Autonomous DB.

- Gestión de Datos y Data Lakes
- Concepto y arquitectura de un Data Lake.
- Diferencia entre Data Lake vs. Data Warehouse.
- Gobernanza de datos y calidad.

👉 Mini-caso práctico: diseñar un flujo conceptual de Data Lake en OCI (Object Storage como Data Lake + Autonomous DB para consultas).
### Bloque 3 (1h 15m) – Procesamiento Paralelo y Distribuido
Introducción al procesamiento paralelo y distribuido

Conceptos básicos: paralelismo, distribución, escalabilidad horizontal.

- Ventajas y desafíos.
- Arquitecturas de clúster para ML (ejemplo: Hadoop + Spark).
- Apache Spark para ML
- Fundamentos: RDDs, DataFrames, Datasets.
- Spark SQL.
- MLlib: modelos distribuidos.

👉 Demo práctica (simulada en local/VM): instalar PySpark y ejecutar una consulta sobre dataset (ej. Titanic).
### Bloque 4 (45m) – Otras Tecnologías Distribuidas
Dask en Python

Comparación con Spark.

👉 Demo práctica: paralelizar operaciones en Pandas con dask.dataframe.

- TensorFlow Distributed y PyTorch Distributed
- Concepto de entrenamiento en múltiples nodos.
- Estrategias: data parallelism vs. model parallelism.
- Ejemplo de entrenamiento simple con TensorFlow MirroredStrategy.
- GPU Computing
- Ventajas de GPUs en ML/DL.

👉 Ejemplo conceptual: usar Colab con GPU para entrenamiento acelerado.
### 📦 Materiales de apoyo
Slides: resumen conceptual de almacenamiento, bases de datos, ETL, Data Lakes y procesamiento distribuido.

Labs prácticos:
- Lab 1: Object Storage + Autonomous DB (OCI).
- Lab 2: PySpark en VM (dataset Titanic).
- Lab 3: Dask en Python.